{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80d66603",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-07-12T12:55:33.895444Z",
     "iopub.status.busy": "2022-07-12T12:55:33.894684Z",
     "iopub.status.idle": "2022-07-12T12:55:33.909462Z",
     "shell.execute_reply": "2022-07-12T12:55:33.908544Z"
    },
    "papermill": {
     "duration": 0.025361,
     "end_time": "2022-07-12T12:55:33.911814",
     "exception": false,
     "start_time": "2022-07-12T12:55:33.886453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/title-generation/sample_submission.csv\n",
      "/kaggle/input/title-generation/vocs.pkl\n",
      "/kaggle/input/title-generation/train.csv\n",
      "/kaggle/input/title-generation/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e59dff",
   "metadata": {
    "papermill": {
     "duration": 0.00535,
     "end_time": "2022-07-12T12:55:33.923149",
     "exception": false,
     "start_time": "2022-07-12T12:55:33.917799",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Clean train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8704489",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T12:55:33.935341Z",
     "iopub.status.busy": "2022-07-12T12:55:33.935006Z",
     "iopub.status.idle": "2022-07-12T12:55:33.938811Z",
     "shell.execute_reply": "2022-07-12T12:55:33.937959Z"
    },
    "papermill": {
     "duration": 0.011804,
     "end_time": "2022-07-12T12:55:33.940517",
     "exception": false,
     "start_time": "2022-07-12T12:55:33.928713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', -1)\n",
    "# def la(df: pd.DataFrame):\n",
    "#     left_aligned_df = df.style.set_properties(**{'text-align': 'left'})\n",
    "#     left_aligned_df = left_aligned_df.set_table_styles(\n",
    "#         [dict(selector='th', props=[('text-align', 'left')])]\n",
    "#     )\n",
    "#     return left_aligned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d99ce8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T12:55:33.952798Z",
     "iopub.status.busy": "2022-07-12T12:55:33.952526Z",
     "iopub.status.idle": "2022-07-12T12:55:48.236900Z",
     "shell.execute_reply": "2022-07-12T12:55:48.236086Z"
    },
    "papermill": {
     "duration": 14.293123,
     "end_time": "2022-07-12T12:55:48.239361",
     "exception": false,
     "start_time": "2022-07-12T12:55:33.946238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:24: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"/kaggle/input/title-generation/train.csv\")\n",
    "train['A_len_ch'] = train.abstract.str.len()\n",
    "train['T_len_ch'] = train.title.str.len()\n",
    "train['A_len_w'] = train.abstract.str.split().map(len)\n",
    "train['T_len_w'] = train.title.str.split().map(len)\n",
    "\n",
    "# –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä—ã, –≥–¥–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤/—Å–ª–æ–≤ –≤ –∞–±—Å—Ç—Ä–∞–∫—Ç–µ –±–æ–ª—å—à–µ –∏–ª–∏ —Ä–∞–≤–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–∏–º–≤–æ–ª–æ–≤/—Å–ª–æ–≤ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏\n",
    "train = train[train.A_len_ch >= train.T_len_ch]\n",
    "train = train[train.A_len_w >= train.T_len_w]\n",
    "\n",
    "# —É–¥–∞–ª—è–µ–º –≤—Å–µ –Ω–∞—á–∏–Ω–∞—é—â–µ–µ—Å—è —Å comment/rejoinder/discussion of\n",
    "for to_delete_startswith in [\"comment\", \"rejoinder\", \"discussion of\"]:\n",
    "    train = train[~train.abstract.str.startswith(to_delete_startswith)]\n",
    "    train = train[~train.title.str.startswith(to_delete_startswith)]\n",
    "\n",
    "# —É–¥–∞–ª—è–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∞–±—Å—Ç—Ä–∞–∫—Ç—ã —Å –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–æ–º withdrawn, –∞ —Ç–∞–∫ –∂–µ –ª—é–±—ã–µ —Å no abstract\n",
    "train = train[~(train.abstract.str.contains(\"withdrawn\", case=False) & (train.A_len_w < 20))]\n",
    "train = train[~train.abstract.str.contains(\"no abstract\", case=False)]\n",
    "\n",
    "# —É–¥–∞–ª—è–µ–º –ø–æ–ª–Ω—ã–µ –¥—É–±–ª–∏–∫–∞—Ç—ã\n",
    "train = pd.DataFrame.drop_duplicates(train)\n",
    "\n",
    "# –æ—Å—Ç–∞–≤–ª—è–µ–º –∏–∑ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è —Ç–æ–ª—å–∫–æ —Ç–µ –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ abstract, –∫–æ—Ç–æ—Ä—ã–µ –∏–º–µ—é—Ç –º–µ–Ω—å—à–∏–π –ø–æ –¥–ª–∏–Ω–µ title\n",
    "train = train[~train.sort_values(by=[\"T_len_ch\"]).abstract.duplicated(keep=\"first\")]\n",
    "\n",
    "train.to_csv(\"run_train.csv\", index=False)\n",
    "\n",
    "del train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2cc504",
   "metadata": {
    "papermill": {
     "duration": 0.005619,
     "end_time": "2022-07-12T12:55:48.250800",
     "exception": false,
     "start_time": "2022-07-12T12:55:48.245181",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Fine tuning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75454f6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T12:55:48.263451Z",
     "iopub.status.busy": "2022-07-12T12:55:48.263129Z",
     "iopub.status.idle": "2022-07-12T12:55:48.267102Z",
     "shell.execute_reply": "2022-07-12T12:55:48.266288Z"
    },
    "papermill": {
     "duration": 0.01249,
     "end_time": "2022-07-12T12:55:48.268776",
     "exception": false,
     "start_time": "2022-07-12T12:55:48.256286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c81f745d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T12:55:48.281253Z",
     "iopub.status.busy": "2022-07-12T12:55:48.280602Z",
     "iopub.status.idle": "2022-07-12T12:56:25.048076Z",
     "shell.execute_reply": "2022-07-12T12:56:25.046975Z"
    },
    "papermill": {
     "duration": 36.775854,
     "end_time": "2022-07-12T12:56:25.050179",
     "exception": false,
     "start_time": "2022-07-12T12:55:48.274325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\r\n",
      "  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\r\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from rouge_score) (1.16.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from rouge_score) (1.21.6)\r\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from rouge_score) (3.2.4)\r\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.7/site-packages (from rouge_score) (1.0.0)\r\n",
      "Installing collected packages: rouge_score\r\n",
      "Successfully installed rouge_score-0.0.4\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mRequirement already satisfied: wandb in /opt/conda/lib/python3.7/site-packages (0.12.16)\r\n",
      "Collecting wandb\r\n",
      "  Downloading wandb-0.12.21-py2.py3-none-any.whl (1.8 MB)\r\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.1.27)\r\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.3)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from wandb) (6.0)\r\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.9.0)\r\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (8.0.4)\r\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.7/site-packages (from wandb) (0.1.2)\r\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.5.12)\r\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.16.0)\r\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.7/site-packages (from wandb) (1.2.3)\r\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (0.4.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from wandb) (59.8.0)\r\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.0.9)\r\n",
      "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.20.1)\r\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.27.1)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (4.11.4)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (4.2.0)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.3)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2022.5.18.1)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.26.9)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.5)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (3.8.0)\r\n",
      "Installing collected packages: wandb\r\n",
      "  Attempting uninstall: wandb\r\n",
      "    Found existing installation: wandb 0.12.16\r\n",
      "    Uninstalling wandb-0.12.16:\r\n",
      "      Successfully uninstalled wandb-0.12.16\r\n",
      "Successfully installed wandb-0.12.21\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mCloning into 'transformers'...\r\n",
      "remote: Enumerating objects: 100556, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (21/21), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (16/16), done.\u001b[K\r\n",
      "remote: Total 100556 (delta 6), reused 13 (delta 3), pack-reused 100535\u001b[K\r\n",
      "Receiving objects: 100% (100556/100556), 94.01 MiB | 27.65 MiB/s, done.\r\n",
      "Resolving deltas: 100% (74188/74188), done.\r\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "100 30199  100 30199    0     0   201k      0 --:--:-- --:--:-- --:--:--  201k\r\n",
      "CITATION.cff\t    README.md\t       examples        setup.py\r\n",
      "CODE_OF_CONDUCT.md  README_ko.md       hubconf.py      src\r\n",
      "CONTRIBUTING.md     README_zh-hans.md  model_cards     templates\r\n",
      "ISSUES.md\t    README_zh-hant.md  notebooks       tests\r\n",
      "LICENSE\t\t    conftest.py        pyproject.toml  utils\r\n",
      "MANIFEST.in\t    docker\t       scripts\t       valohai.yaml\r\n",
      "Makefile\t    docs\t       setup.cfg\r\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score\n",
    "!pip install wandb --upgrade\n",
    "\n",
    "!git clone https://github.com/huggingface/transformers.git\n",
    "# –ó–∞–º–µ–Ω—è–µ–º —Ñ–∞–π–ª run_summarization.py –Ω–∞ –≤–µ—Ä—Å–∏—é, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–∞ —Å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–π –Ω–∞ –∫–∞–≥–≥–ª–µ –≤–µ—Ä—Å–∏–µ–π transformers\n",
    "!curl https://raw.githubusercontent.com/huggingface/transformers/79d28e80b6f5a37c3f6bacf3fd708963c58b68fb/examples/pytorch/summarization/run_summarization.py \\\n",
    "    -o transformers/examples/pytorch/summarization/run_summarization.py\n",
    "\n",
    "!ls ./transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9216f4a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T12:56:25.082245Z",
     "iopub.status.busy": "2022-07-12T12:56:25.081878Z",
     "iopub.status.idle": "2022-07-12T12:56:25.085826Z",
     "shell.execute_reply": "2022-07-12T12:56:25.085095Z"
    },
    "papermill": {
     "duration": 0.0224,
     "end_time": "2022-07-12T12:56:25.087600",
     "exception": false,
     "start_time": "2022-07-12T12:56:25.065200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pd.read_csv(\"/kaggle/input/title-generation/train.csv\")[:500].to_csv(\"run_train.csv\", index=False)\n",
    "# pd.read_csv(\"/kaggle/input/title-generation/train.csv\")[1000:500].to_csv(\"run_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b08e465",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T12:56:25.117691Z",
     "iopub.status.busy": "2022-07-12T12:56:25.116848Z",
     "iopub.status.idle": "2022-07-12T12:56:26.412024Z",
     "shell.execute_reply": "2022-07-12T12:56:26.411051Z"
    },
    "papermill": {
     "duration": 1.312186,
     "end_time": "2022-07-12T12:56:26.413994",
     "exception": false,
     "start_time": "2022-07-12T12:56:25.101808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "# I have saved my API token with \"wandb_api\" as Label. \n",
    "# If you use some other Label make sure to change the same below. \n",
    "wandb_api = user_secrets.get_secret(\"wandb_api\") \n",
    "\n",
    "wandb.login(key=wandb_api)\n",
    "\n",
    "# wandb.init(project=\"Stepik-NN-and-NLP 7.Final ATG fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d75b2d6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T12:56:26.446836Z",
     "iopub.status.busy": "2022-07-12T12:56:26.445960Z",
     "iopub.status.idle": "2022-07-12T21:47:43.000758Z",
     "shell.execute_reply": "2022-07-12T21:47:42.999641Z"
    },
    "papermill": {
     "duration": 31876.57373,
     "end_time": "2022-07-12T21:47:43.003351",
     "exception": false,
     "start_time": "2022-07-12T12:56:26.429621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-e03253f123116e83/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\r\n",
      "Downloading data files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 5405.03it/s]\r\n",
      "Extracting data files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 1073.81it/s]\r\n",
      "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-e03253f123116e83/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\r\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 291.64it/s]\r\n",
      "[INFO|hub.py:583] 2022-07-12 12:56:37,300 >> https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpdord2me8\r\n",
      "Downloading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.55k/1.55k [00:00<00:00, 1.35MB/s]\r\n",
      "[INFO|hub.py:587] 2022-07-12 12:56:37,404 >> storing https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/199ab6c0f28e763098fd3ea09fd68a0928bb297d0f76b9f3375e8a1d652748f9.930264180d256e6fe8e4ba6a728dd80e969493c23d4caa0a6f943614c52d34ab\r\n",
      "[INFO|hub.py:595] 2022-07-12 12:56:37,405 >> creating metadata file for /root/.cache/huggingface/transformers/199ab6c0f28e763098fd3ea09fd68a0928bb297d0f76b9f3375e8a1d652748f9.930264180d256e6fe8e4ba6a728dd80e969493c23d4caa0a6f943614c52d34ab\r\n",
      "[INFO|configuration_utils.py:654] 2022-07-12 12:56:37,405 >> loading configuration file https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/199ab6c0f28e763098fd3ea09fd68a0928bb297d0f76b9f3375e8a1d652748f9.930264180d256e6fe8e4ba6a728dd80e969493c23d4caa0a6f943614c52d34ab\r\n",
      "[INFO|configuration_utils.py:690] 2022-07-12 12:56:37,408 >> Model config BartConfig {\r\n",
      "  \"_name_or_path\": \"facebook/bart-large-cnn\",\r\n",
      "  \"_num_labels\": 3,\r\n",
      "  \"activation_dropout\": 0.0,\r\n",
      "  \"activation_function\": \"gelu\",\r\n",
      "  \"add_final_layer_norm\": false,\r\n",
      "  \"architectures\": [\r\n",
      "    \"BartForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"attention_dropout\": 0.0,\r\n",
      "  \"bos_token_id\": 0,\r\n",
      "  \"classif_dropout\": 0.0,\r\n",
      "  \"classifier_dropout\": 0.0,\r\n",
      "  \"d_model\": 1024,\r\n",
      "  \"decoder_attention_heads\": 16,\r\n",
      "  \"decoder_ffn_dim\": 4096,\r\n",
      "  \"decoder_layerdrop\": 0.0,\r\n",
      "  \"decoder_layers\": 12,\r\n",
      "  \"decoder_start_token_id\": 2,\r\n",
      "  \"dropout\": 0.1,\r\n",
      "  \"early_stopping\": true,\r\n",
      "  \"encoder_attention_heads\": 16,\r\n",
      "  \"encoder_ffn_dim\": 4096,\r\n",
      "  \"encoder_layerdrop\": 0.0,\r\n",
      "  \"encoder_layers\": 12,\r\n",
      "  \"eos_token_id\": 2,\r\n",
      "  \"force_bos_token_to_be_generated\": true,\r\n",
      "  \"forced_bos_token_id\": 0,\r\n",
      "  \"forced_eos_token_id\": 2,\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"id2label\": {\r\n",
      "    \"0\": \"LABEL_0\",\r\n",
      "    \"1\": \"LABEL_1\",\r\n",
      "    \"2\": \"LABEL_2\"\r\n",
      "  },\r\n",
      "  \"init_std\": 0.02,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"label2id\": {\r\n",
      "    \"LABEL_0\": 0,\r\n",
      "    \"LABEL_1\": 1,\r\n",
      "    \"LABEL_2\": 2\r\n",
      "  },\r\n",
      "  \"length_penalty\": 2.0,\r\n",
      "  \"max_length\": 142,\r\n",
      "  \"max_position_embeddings\": 1024,\r\n",
      "  \"min_length\": 56,\r\n",
      "  \"model_type\": \"bart\",\r\n",
      "  \"no_repeat_ngram_size\": 3,\r\n",
      "  \"normalize_before\": false,\r\n",
      "  \"num_beams\": 4,\r\n",
      "  \"num_hidden_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 1,\r\n",
      "  \"prefix\": \" \",\r\n",
      "  \"scale_embedding\": false,\r\n",
      "  \"task_specific_params\": {\r\n",
      "    \"summarization\": {\r\n",
      "      \"early_stopping\": true,\r\n",
      "      \"length_penalty\": 2.0,\r\n",
      "      \"max_length\": 142,\r\n",
      "      \"min_length\": 56,\r\n",
      "      \"no_repeat_ngram_size\": 3,\r\n",
      "      \"num_beams\": 4\r\n",
      "    }\r\n",
      "  },\r\n",
      "  \"transformers_version\": \"4.18.0\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 50264\r\n",
      "}\r\n",
      "\r\n",
      "[INFO|tokenization_auto.py:344] 2022-07-12 12:56:37,510 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\r\n",
      "[INFO|configuration_utils.py:654] 2022-07-12 12:56:37,607 >> loading configuration file https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/199ab6c0f28e763098fd3ea09fd68a0928bb297d0f76b9f3375e8a1d652748f9.930264180d256e6fe8e4ba6a728dd80e969493c23d4caa0a6f943614c52d34ab\r\n",
      "[INFO|configuration_utils.py:690] 2022-07-12 12:56:37,609 >> Model config BartConfig {\r\n",
      "  \"_name_or_path\": \"facebook/bart-large-cnn\",\r\n",
      "  \"_num_labels\": 3,\r\n",
      "  \"activation_dropout\": 0.0,\r\n",
      "  \"activation_function\": \"gelu\",\r\n",
      "  \"add_final_layer_norm\": false,\r\n",
      "  \"architectures\": [\r\n",
      "    \"BartForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"attention_dropout\": 0.0,\r\n",
      "  \"bos_token_id\": 0,\r\n",
      "  \"classif_dropout\": 0.0,\r\n",
      "  \"classifier_dropout\": 0.0,\r\n",
      "  \"d_model\": 1024,\r\n",
      "  \"decoder_attention_heads\": 16,\r\n",
      "  \"decoder_ffn_dim\": 4096,\r\n",
      "  \"decoder_layerdrop\": 0.0,\r\n",
      "  \"decoder_layers\": 12,\r\n",
      "  \"decoder_start_token_id\": 2,\r\n",
      "  \"dropout\": 0.1,\r\n",
      "  \"early_stopping\": true,\r\n",
      "  \"encoder_attention_heads\": 16,\r\n",
      "  \"encoder_ffn_dim\": 4096,\r\n",
      "  \"encoder_layerdrop\": 0.0,\r\n",
      "  \"encoder_layers\": 12,\r\n",
      "  \"eos_token_id\": 2,\r\n",
      "  \"force_bos_token_to_be_generated\": true,\r\n",
      "  \"forced_bos_token_id\": 0,\r\n",
      "  \"forced_eos_token_id\": 2,\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"id2label\": {\r\n",
      "    \"0\": \"LABEL_0\",\r\n",
      "    \"1\": \"LABEL_1\",\r\n",
      "    \"2\": \"LABEL_2\"\r\n",
      "  },\r\n",
      "  \"init_std\": 0.02,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"label2id\": {\r\n",
      "    \"LABEL_0\": 0,\r\n",
      "    \"LABEL_1\": 1,\r\n",
      "    \"LABEL_2\": 2\r\n",
      "  },\r\n",
      "  \"length_penalty\": 2.0,\r\n",
      "  \"max_length\": 142,\r\n",
      "  \"max_position_embeddings\": 1024,\r\n",
      "  \"min_length\": 56,\r\n",
      "  \"model_type\": \"bart\",\r\n",
      "  \"no_repeat_ngram_size\": 3,\r\n",
      "  \"normalize_before\": false,\r\n",
      "  \"num_beams\": 4,\r\n",
      "  \"num_hidden_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 1,\r\n",
      "  \"prefix\": \" \",\r\n",
      "  \"scale_embedding\": false,\r\n",
      "  \"task_specific_params\": {\r\n",
      "    \"summarization\": {\r\n",
      "      \"early_stopping\": true,\r\n",
      "      \"length_penalty\": 2.0,\r\n",
      "      \"max_length\": 142,\r\n",
      "      \"min_length\": 56,\r\n",
      "      \"no_repeat_ngram_size\": 3,\r\n",
      "      \"num_beams\": 4\r\n",
      "    }\r\n",
      "  },\r\n",
      "  \"transformers_version\": \"4.18.0\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 50264\r\n",
      "}\r\n",
      "\r\n",
      "[INFO|hub.py:583] 2022-07-12 12:56:37,813 >> https://huggingface.co/facebook/bart-large-cnn/resolve/main/vocab.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpjjxzh64k\r\n",
      "Downloading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 878k/878k [00:00<00:00, 7.66MB/s]\r\n",
      "[INFO|hub.py:587] 2022-07-12 12:56:38,072 >> storing https://huggingface.co/facebook/bart-large-cnn/resolve/main/vocab.json in cache at /root/.cache/huggingface/transformers/4d8eeedc3498bc73a4b72411ebb3219209b305663632d77a6f16e60790b18038.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\r\n",
      "[INFO|hub.py:595] 2022-07-12 12:56:38,072 >> creating metadata file for /root/.cache/huggingface/transformers/4d8eeedc3498bc73a4b72411ebb3219209b305663632d77a6f16e60790b18038.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\r\n",
      "[INFO|hub.py:583] 2022-07-12 12:56:38,204 >> https://huggingface.co/facebook/bart-large-cnn/resolve/main/merges.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpp4n792c4\r\n",
      "Downloading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 446k/446k [00:00<00:00, 4.57MB/s]\r\n",
      "[INFO|hub.py:587] 2022-07-12 12:56:38,422 >> storing https://huggingface.co/facebook/bart-large-cnn/resolve/main/merges.txt in cache at /root/.cache/huggingface/transformers/0ddddd3ca9e107b17a6901c92543692272af1c3238a8d7549fa937ba0057bbcf.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\r\n",
      "[INFO|hub.py:595] 2022-07-12 12:56:38,422 >> creating metadata file for /root/.cache/huggingface/transformers/0ddddd3ca9e107b17a6901c92543692272af1c3238a8d7549fa937ba0057bbcf.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\r\n",
      "[INFO|hub.py:583] 2022-07-12 12:56:38,522 >> https://huggingface.co/facebook/bart-large-cnn/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp5sehc2w9\r\n",
      "Downloading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.29M/1.29M [00:00<00:00, 8.61MB/s]\r\n",
      "[INFO|hub.py:587] 2022-07-12 12:56:38,811 >> storing https://huggingface.co/facebook/bart-large-cnn/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/55c96bd962ce1d360fde4947619318f1b4eb551430de678044699cbfeb99de6a.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\r\n",
      "[INFO|hub.py:595] 2022-07-12 12:56:38,811 >> creating metadata file for /root/.cache/huggingface/transformers/55c96bd962ce1d360fde4947619318f1b4eb551430de678044699cbfeb99de6a.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\r\n",
      "[INFO|tokenization_utils_base.py:1778] 2022-07-12 12:56:39,127 >> loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/4d8eeedc3498bc73a4b72411ebb3219209b305663632d77a6f16e60790b18038.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\r\n",
      "[INFO|tokenization_utils_base.py:1778] 2022-07-12 12:56:39,127 >> loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/0ddddd3ca9e107b17a6901c92543692272af1c3238a8d7549fa937ba0057bbcf.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\r\n",
      "[INFO|tokenization_utils_base.py:1778] 2022-07-12 12:56:39,127 >> loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/55c96bd962ce1d360fde4947619318f1b4eb551430de678044699cbfeb99de6a.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\r\n",
      "[INFO|tokenization_utils_base.py:1778] 2022-07-12 12:56:39,127 >> loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/added_tokens.json from cache at None\r\n",
      "[INFO|tokenization_utils_base.py:1778] 2022-07-12 12:56:39,127 >> loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/special_tokens_map.json from cache at None\r\n",
      "[INFO|tokenization_utils_base.py:1778] 2022-07-12 12:56:39,127 >> loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/tokenizer_config.json from cache at None\r\n",
      "[INFO|configuration_utils.py:654] 2022-07-12 12:56:39,220 >> loading configuration file https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/199ab6c0f28e763098fd3ea09fd68a0928bb297d0f76b9f3375e8a1d652748f9.930264180d256e6fe8e4ba6a728dd80e969493c23d4caa0a6f943614c52d34ab\r\n",
      "[INFO|configuration_utils.py:690] 2022-07-12 12:56:39,221 >> Model config BartConfig {\r\n",
      "  \"_name_or_path\": \"facebook/bart-large-cnn\",\r\n",
      "  \"_num_labels\": 3,\r\n",
      "  \"activation_dropout\": 0.0,\r\n",
      "  \"activation_function\": \"gelu\",\r\n",
      "  \"add_final_layer_norm\": false,\r\n",
      "  \"architectures\": [\r\n",
      "    \"BartForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"attention_dropout\": 0.0,\r\n",
      "  \"bos_token_id\": 0,\r\n",
      "  \"classif_dropout\": 0.0,\r\n",
      "  \"classifier_dropout\": 0.0,\r\n",
      "  \"d_model\": 1024,\r\n",
      "  \"decoder_attention_heads\": 16,\r\n",
      "  \"decoder_ffn_dim\": 4096,\r\n",
      "  \"decoder_layerdrop\": 0.0,\r\n",
      "  \"decoder_layers\": 12,\r\n",
      "  \"decoder_start_token_id\": 2,\r\n",
      "  \"dropout\": 0.1,\r\n",
      "  \"early_stopping\": true,\r\n",
      "  \"encoder_attention_heads\": 16,\r\n",
      "  \"encoder_ffn_dim\": 4096,\r\n",
      "  \"encoder_layerdrop\": 0.0,\r\n",
      "  \"encoder_layers\": 12,\r\n",
      "  \"eos_token_id\": 2,\r\n",
      "  \"force_bos_token_to_be_generated\": true,\r\n",
      "  \"forced_bos_token_id\": 0,\r\n",
      "  \"forced_eos_token_id\": 2,\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"id2label\": {\r\n",
      "    \"0\": \"LABEL_0\",\r\n",
      "    \"1\": \"LABEL_1\",\r\n",
      "    \"2\": \"LABEL_2\"\r\n",
      "  },\r\n",
      "  \"init_std\": 0.02,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"label2id\": {\r\n",
      "    \"LABEL_0\": 0,\r\n",
      "    \"LABEL_1\": 1,\r\n",
      "    \"LABEL_2\": 2\r\n",
      "  },\r\n",
      "  \"length_penalty\": 2.0,\r\n",
      "  \"max_length\": 142,\r\n",
      "  \"max_position_embeddings\": 1024,\r\n",
      "  \"min_length\": 56,\r\n",
      "  \"model_type\": \"bart\",\r\n",
      "  \"no_repeat_ngram_size\": 3,\r\n",
      "  \"normalize_before\": false,\r\n",
      "  \"num_beams\": 4,\r\n",
      "  \"num_hidden_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 1,\r\n",
      "  \"prefix\": \" \",\r\n",
      "  \"scale_embedding\": false,\r\n",
      "  \"task_specific_params\": {\r\n",
      "    \"summarization\": {\r\n",
      "      \"early_stopping\": true,\r\n",
      "      \"length_penalty\": 2.0,\r\n",
      "      \"max_length\": 142,\r\n",
      "      \"min_length\": 56,\r\n",
      "      \"no_repeat_ngram_size\": 3,\r\n",
      "      \"num_beams\": 4\r\n",
      "    }\r\n",
      "  },\r\n",
      "  \"transformers_version\": \"4.18.0\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 50264\r\n",
      "}\r\n",
      "\r\n",
      "[INFO|hub.py:583] 2022-07-12 12:56:39,445 >> https://huggingface.co/facebook/bart-large-cnn/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpp1waajgl\r\n",
      "Downloading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.51G/1.51G [00:34<00:00, 47.7MB/s]\r\n",
      "[INFO|hub.py:587] 2022-07-12 12:57:13,816 >> storing https://huggingface.co/facebook/bart-large-cnn/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/4ccdf4cdc01b790f9f9c636c7695b5d443180e8dbd0cbe49e07aa918dda1cef0.fa29468c10a34ef7f6cfceba3b174d3ccc95f8d755c3ca1b829aff41cc92a300\r\n",
      "[INFO|hub.py:595] 2022-07-12 12:57:14,441 >> creating metadata file for /root/.cache/huggingface/transformers/4ccdf4cdc01b790f9f9c636c7695b5d443180e8dbd0cbe49e07aa918dda1cef0.fa29468c10a34ef7f6cfceba3b174d3ccc95f8d755c3ca1b829aff41cc92a300\r\n",
      "[INFO|modeling_utils.py:1772] 2022-07-12 12:57:14,442 >> loading weights file https://huggingface.co/facebook/bart-large-cnn/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4ccdf4cdc01b790f9f9c636c7695b5d443180e8dbd0cbe49e07aa918dda1cef0.fa29468c10a34ef7f6cfceba3b174d3ccc95f8d755c3ca1b829aff41cc92a300\r\n",
      "[INFO|modeling_utils.py:2057] 2022-07-12 12:57:20,221 >> All model checkpoint weights were used when initializing BartForConditionalGeneration.\r\n",
      "\r\n",
      "[INFO|modeling_utils.py:2066] 2022-07-12 12:57:20,221 >> All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-large-cnn.\r\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\r\n",
      "Running tokenizer on train dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà| 106/106 [01:21<00:00,  1.30ba/s]\r\n",
      "Downloading builder script: 5.60kB [00:00, 2.76MB/s]                            \r\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\r\n",
      "  FutureWarning,\r\n",
      "[INFO|trainer.py:1290] 2022-07-12 12:58:49,252 >> ***** Running training *****\r\n",
      "[INFO|trainer.py:1291] 2022-07-12 12:58:49,253 >>   Num examples = 105030\r\n",
      "[INFO|trainer.py:1292] 2022-07-12 12:58:49,253 >>   Num Epochs = 3\r\n",
      "[INFO|trainer.py:1293] 2022-07-12 12:58:49,253 >>   Instantaneous batch size per device = 4\r\n",
      "[INFO|trainer.py:1294] 2022-07-12 12:58:49,253 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\r\n",
      "[INFO|trainer.py:1295] 2022-07-12 12:58:49,253 >>   Gradient Accumulation steps = 1\r\n",
      "[INFO|trainer.py:1296] 2022-07-12 12:58:49,253 >>   Total optimization steps = 78774\r\n",
      "[INFO|integrations.py:577] 2022-07-12 12:58:49,285 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwisoffe\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20220712_125849-g22bl4ta\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m/kaggle/working/tst-summarization\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/wisoffe/huggingface\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/wisoffe/huggingface/runs/g22bl4ta\u001b[0m\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ‚ñÅ\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ‚ñÅ\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ‚ñÅ\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ‚ñÅ\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ‚ñÅ\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 3.0\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 78774\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 1.0985\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 1.869410966665298e+17\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 1.59976\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 31712.6515\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 9.936\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 2.484\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33m/kaggle/working/tst-summarization\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/wisoffe/huggingface/runs/g22bl4ta\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220712_125849-g22bl4ta/logs\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python transformers/examples/pytorch/summarization/run_summarization.py \\\n",
    "    --model_name_or_path facebook/bart-large-cnn \\\n",
    "    --do_train \\\n",
    "    --train_file \"/kaggle/working/run_train.csv\" \\\n",
    "    --text_column \"abstract\" \\\n",
    "    --summary_column \"title\" \\\n",
    "    --output_dir /kaggle/working/tst-summarization \\\n",
    "    --overwrite_output_dir \\\n",
    "    --per_device_train_batch_size=4 \\\n",
    "    --per_device_eval_batch_size=4 \\\n",
    "    --predict_with_generate \\\n",
    "    --save_total_limit=2\n",
    "#     --source_prefix \"summarize: \" \\\n",
    "#    --load_best_model_at_end=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "444d1e82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T21:47:55.415665Z",
     "iopub.status.busy": "2022-07-12T21:47:55.415187Z",
     "iopub.status.idle": "2022-07-12T21:47:55.420374Z",
     "shell.execute_reply": "2022-07-12T21:47:55.419422Z"
    },
    "papermill": {
     "duration": 6.220009,
     "end_time": "2022-07-12T21:47:55.422450",
     "exception": false,
     "start_time": "2022-07-12T21:47:49.202441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python transformers/examples/pytorch/summarization/run_summarization.py \\\n",
    "#     --model_name_or_path t5-small \\\n",
    "#     --do_train \\\n",
    "#     --do_eval \\\n",
    "#     --train_file \"/kaggle/working/run_train.csv\" \\\n",
    "#     --validation_file \"/kaggle/working/run_test.csv\" \\\n",
    "#     --text_column \"abstract\" \\\n",
    "#     --summary_column \"title\" \\\n",
    "#     --source_prefix \"summarize: \" \\\n",
    "#     --output_dir /kaggle/working/tst-summarization \\\n",
    "#     --overwrite_output_dir \\\n",
    "#     --per_device_train_batch_size=30 \\\n",
    "#     --per_device_eval_batch_size=30 \\\n",
    "#     --predict_with_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8642e7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T21:48:08.157157Z",
     "iopub.status.busy": "2022-07-12T21:48:08.156701Z",
     "iopub.status.idle": "2022-07-12T21:48:09.041126Z",
     "shell.execute_reply": "2022-07-12T21:48:09.039919Z"
    },
    "papermill": {
     "duration": 7.384657,
     "end_time": "2022-07-12T21:48:09.043583",
     "exception": false,
     "start_time": "2022-07-12T21:48:01.658926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1590800\r\n",
      "drwxr-xr-x 5 root root       4096 Jul 12 21:47 .\r\n",
      "drwxr-xr-x 5 root root       4096 Jul 12 12:58 ..\r\n",
      "-rw-r--r-- 1 root root       1030 Jul 12 21:47 README.md\r\n",
      "-rw-r--r-- 1 root root        196 Jul 12 21:47 all_results.json\r\n",
      "drwxr-xr-x 2 root root       4096 Jul 12 21:42 checkpoint-78000\r\n",
      "drwxr-xr-x 2 root root       4096 Jul 12 21:45 checkpoint-78500\r\n",
      "-rw-r--r-- 1 root root       1655 Jul 12 21:47 config.json\r\n",
      "-rw-r--r-- 1 root root     456356 Jul 12 21:47 merges.txt\r\n",
      "-rw-r--r-- 1 root root 1625537793 Jul 12 21:47 pytorch_model.bin\r\n",
      "drwxr-xr-x 3 root root       4096 Jul 12 12:58 runs\r\n",
      "-rw-r--r-- 1 root root        239 Jul 12 21:47 special_tokens_map.json\r\n",
      "-rw-r--r-- 1 root root    2108689 Jul 12 21:47 tokenizer.json\r\n",
      "-rw-r--r-- 1 root root        358 Jul 12 21:47 tokenizer_config.json\r\n",
      "-rw-r--r-- 1 root root        196 Jul 12 21:47 train_results.json\r\n",
      "-rw-r--r-- 1 root root      19768 Jul 12 21:47 trainer_state.json\r\n",
      "-rw-r--r-- 1 root root       3247 Jul 12 21:47 training_args.bin\r\n",
      "-rw-r--r-- 1 root root     798293 Jul 12 21:47 vocab.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la /kaggle/working/tst-summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8409e2",
   "metadata": {
    "papermill": {
     "duration": 5.812894,
     "end_time": "2022-07-12T21:48:21.051954",
     "exception": false,
     "start_time": "2022-07-12T21:48:15.239060",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22d28327",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T21:48:33.188806Z",
     "iopub.status.busy": "2022-07-12T21:48:33.188303Z",
     "iopub.status.idle": "2022-07-12T21:48:39.114885Z",
     "shell.execute_reply": "2022-07-12T21:48:39.113994Z"
    },
    "papermill": {
     "duration": 11.955233,
     "end_time": "2022-07-12T21:48:39.117364",
     "exception": false,
     "start_time": "2022-07-12T21:48:27.162131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85a14580",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T21:48:50.996238Z",
     "iopub.status.busy": "2022-07-12T21:48:50.995588Z",
     "iopub.status.idle": "2022-07-12T21:48:51.046875Z",
     "shell.execute_reply": "2022-07-12T21:48:51.045934Z"
    },
    "papermill": {
     "duration": 5.850386,
     "end_time": "2022-07-12T21:48:51.049227",
     "exception": false,
     "start_time": "2022-07-12T21:48:45.198841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH_TO_FINETUNED = '/kaggle/working/tst-summarization'\n",
    "LOCAL_FILES_ONLY = False\n",
    "WHITESPACE_HANDLER = lambda k: re.sub('\\s+', ' ', re.sub('\\n+', ' ', k.strip()))\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model_names = {\n",
    "    'bart-large-cnn-finetuned-wisoffe': '/kaggle/working/tst-summarization'\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dba342ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T21:49:02.917743Z",
     "iopub.status.busy": "2022-07-12T21:49:02.917366Z",
     "iopub.status.idle": "2022-07-12T21:49:02.924952Z",
     "shell.execute_reply": "2022-07-12T21:49:02.923993Z"
    },
    "papermill": {
     "duration": 5.830872,
     "end_time": "2022-07-12T21:49:02.926970",
     "exception": false,
     "start_time": "2022-07-12T21:48:57.096098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " def inference(text, model, tokenizer, out_max_length=27, num_beams=4):\n",
    "    input_ids = tokenizer(\n",
    "        [WHITESPACE_HANDLER(text)],\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    output_ids = model.generate(\n",
    "        input_ids=input_ids.to(device),\n",
    "        max_length=out_max_length, #in tokens\n",
    "        no_repeat_ngram_size=2,\n",
    "        num_beams=num_beams\n",
    "    )[0]\n",
    "\n",
    "    summary = tokenizer.decode(\n",
    "        output_ids,\n",
    "        skip_special_tokens=True,\n",
    "        clean_up_tokenization_spaces=False\n",
    "    )\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "736e7d6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T21:49:15.412067Z",
     "iopub.status.busy": "2022-07-12T21:49:15.411478Z",
     "iopub.status.idle": "2022-07-12T21:49:18.657833Z",
     "shell.execute_reply": "2022-07-12T21:49:18.656917Z"
    },
    "papermill": {
     "duration": 9.661208,
     "end_time": "2022-07-12T21:49:18.660138",
     "exception": false,
     "start_time": "2022-07-12T21:49:08.998930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Most sequence transformation models use recurr...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The doc2vec approach was introduced as an exte...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSTM models can vary greatly depending on sequ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A joint learning process of alignment and tran...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Current unsupervised image-to-image translatio...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>subsystem codes are the most versatile class o...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>we study dirac-harmonic maps from degenerating...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>in this note we study kloosterman sums twisted...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>we obtain the rate of growth of long strange s...</td>\n",
       "      <td>long strange segments, ruin probabilities and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>the time evolution of a spin-1/2 particle unde...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              abstract  \\\n",
       "0    Most sequence transformation models use recurr...   \n",
       "1    The doc2vec approach was introduced as an exte...   \n",
       "2    LSTM models can vary greatly depending on sequ...   \n",
       "3    A joint learning process of alignment and tran...   \n",
       "4    Current unsupervised image-to-image translatio...   \n",
       "..                                                 ...   \n",
       "995  subsystem codes are the most versatile class o...   \n",
       "996  we study dirac-harmonic maps from degenerating...   \n",
       "997  in this note we study kloosterman sums twisted...   \n",
       "998  we obtain the rate of growth of long strange s...   \n",
       "999  the time evolution of a spin-1/2 particle unde...   \n",
       "\n",
       "                                                 title  \n",
       "0                                                  NaN  \n",
       "1                                                  NaN  \n",
       "2                                                  NaN  \n",
       "3                                                  NaN  \n",
       "4                                                  NaN  \n",
       "..                                                 ...  \n",
       "995                                                NaN  \n",
       "996                                                NaN  \n",
       "997                                                NaN  \n",
       "998  long strange segments, ruin probabilities and ...  \n",
       "999                                                NaN  \n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"/kaggle/input/title-generation/train.csv\")\n",
    "test = pd.read_csv(\"/kaggle/input/title-generation/test.csv\")\n",
    "#—Ç.–∫. –≤ —Ç—Ä–µ–π–Ω –µ—Å—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∏—Ö –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —É–¥–∞–ª–∏—Ç—å\n",
    "cross = test.merge(train.drop_duplicates(subset=['abstract']), on='abstract', how='left')\n",
    "cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b2f59b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T21:49:30.758945Z",
     "iopub.status.busy": "2022-07-12T21:49:30.758558Z",
     "iopub.status.idle": "2022-07-12T21:53:00.474594Z",
     "shell.execute_reply": "2022-07-12T21:53:00.473499Z"
    },
    "papermill": {
     "duration": 215.87809,
     "end_time": "2022-07-12T21:53:00.477534",
     "exception": false,
     "start_time": "2022-07-12T21:49:24.599444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bart-large-cnn-finetuned-wisoffe\n"
     ]
    }
   ],
   "source": [
    "predicted_titles_filename_suffixes = []\n",
    "OUT_MAX_LENGTH = 20\n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    predicted_titles_filename_suffixes.append(f\"_{model_name}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_names[model_name], local_files_only=LOCAL_FILES_ONLY)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_names[model_name], local_files_only=LOCAL_FILES_ONLY)\n",
    "    model.to(device)\n",
    "    predicted_titles = cross.copy()\n",
    "    #predicted_titles = predicted_titles.sample(5) #only for test on errors\n",
    "    predicted_titles\n",
    "    predicted_titles['title'] = predicted_titles.apply(lambda x: x.title if x.title is not np.NaN \n",
    "                                                        else inference(x.abstract, model, tokenizer, out_max_length=OUT_MAX_LENGTH).lower(), \n",
    "                                                        axis=1)\n",
    "    \n",
    "    # –í—Ä–µ–º–µ–Ω–Ω—ã–π –∫–æ—Å—Ç—ã–ª—å, —Ç.–∫. generate_csv –Ω–µ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è –≤ –æ–¥–Ω–æ —Å–ª–æ–≤–æ\n",
    "    predicted_titles['title'] = predicted_titles.title.map(lambda x: x if len(x.split()) > 1 else 'of the and in for a on with to model')\n",
    "    \n",
    "    predicted_titles.to_csv(f'predicted_titles{predicted_titles_filename_suffixes[-1]}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55141777",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T21:53:13.599640Z",
     "iopub.status.busy": "2022-07-12T21:53:13.599223Z",
     "iopub.status.idle": "2022-07-12T21:53:14.445062Z",
     "shell.execute_reply": "2022-07-12T21:53:14.443746Z"
    },
    "papermill": {
     "duration": 7.091896,
     "end_time": "2022-07-12T21:53:14.447680",
     "exception": false,
     "start_time": "2022-07-12T21:53:07.355784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook__.ipynb\t\t\t\t       transformers\r\n",
      "predicted_titles_bart-large-cnn-finetuned-wisoffe.csv  tst-summarization\r\n",
      "run_train.csv\t\t\t\t\t       wandb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2069d858",
   "metadata": {
    "papermill": {
     "duration": 5.927687,
     "end_time": "2022-07-12T21:53:26.589386",
     "exception": false,
     "start_time": "2022-07-12T21:53:20.661699",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### –î–µ–ª–∞–µ–º submission –≤ Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "869475b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T21:53:39.262880Z",
     "iopub.status.busy": "2022-07-12T21:53:39.262431Z",
     "iopub.status.idle": "2022-07-12T21:53:40.534238Z",
     "shell.execute_reply": "2022-07-12T21:53:40.533226Z"
    },
    "papermill": {
     "duration": 7.77324,
     "end_time": "2022-07-12T21:53:40.536647",
     "exception": false,
     "start_time": "2022-07-12T21:53:32.763407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.util import ngrams\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "\n",
    "def generate_csv(input_file='predicted_titles.csv',\n",
    "                 output_file='submission.csv',\n",
    "                 voc_file='/kaggle/input/title-generation/vocs.pkl'):\n",
    "    '''\n",
    "    Generates file in format required for submitting result to Kaggle\n",
    "    \n",
    "    Parameters:\n",
    "        input_file (str) : path to csv file with your predicted titles.\n",
    "                           Should have two fields: abstract and title\n",
    "        output_file (str) : path to output submission file\n",
    "        voc_file (str) : path to voc.pkl file\n",
    "    '''\n",
    "    data = pd.read_csv(input_file)\n",
    "    with open(voc_file, 'rb') as voc_file:\n",
    "        vocs = pickle.load(voc_file)\n",
    "\n",
    "    with open(output_file, 'w') as res_file:\n",
    "        res_file.write('Id,Predict\\n')\n",
    "        \n",
    "    output_idx = 0\n",
    "    for row_idx, row in data.iterrows():\n",
    "        trg = row['title']\n",
    "        trg = trg.translate(str.maketrans('', '', string.punctuation)).lower().split()\n",
    "        trg.extend(['_'.join(ngram) for ngram in list(ngrams(trg, 2)) + list(ngrams(trg, 3))])\n",
    "        \n",
    "        VOCAB_stoi = vocs[row_idx]\n",
    "        trg_intersection = set(VOCAB_stoi.keys()).intersection(set(trg))\n",
    "        trg_vec = np.zeros(len(VOCAB_stoi))    \n",
    "\n",
    "        for word in trg_intersection:\n",
    "            trg_vec[VOCAB_stoi[word]] = 1\n",
    "\n",
    "        with open(output_file, 'a') as res_file:\n",
    "            for is_word in trg_vec:\n",
    "                res_file.write('{0},{1}\\n'.format(output_idx, int(is_word)))\n",
    "                output_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74563019",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T21:53:53.316628Z",
     "iopub.status.busy": "2022-07-12T21:53:53.316217Z",
     "iopub.status.idle": "2022-07-12T21:53:54.366882Z",
     "shell.execute_reply": "2022-07-12T21:53:54.365896Z"
    },
    "papermill": {
     "duration": 7.384306,
     "end_time": "2022-07-12T21:53:54.369295",
     "exception": false,
     "start_time": "2022-07-12T21:53:46.984989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for suffix in predicted_titles_filename_suffixes:\n",
    "    generate_csv(input_file=f'predicted_titles{suffix}.csv',\n",
    "                 output_file=f'submission{suffix}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "318d9972",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T21:54:06.603252Z",
     "iopub.status.busy": "2022-07-12T21:54:06.602826Z",
     "iopub.status.idle": "2022-07-12T21:54:07.466501Z",
     "shell.execute_reply": "2022-07-12T21:54:07.465158Z"
    },
    "papermill": {
     "duration": 7.184855,
     "end_time": "2022-07-12T21:54:07.469936",
     "exception": false,
     "start_time": "2022-07-12T21:54:00.285081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook__.ipynb\t\t\t\t       transformers\r\n",
      "predicted_titles_bart-large-cnn-finetuned-wisoffe.csv  tst-summarization\r\n",
      "run_train.csv\t\t\t\t\t       wandb\r\n",
      "submission_bart-large-cnn-finetuned-wisoffe.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53a54820",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T21:54:20.179898Z",
     "iopub.status.busy": "2022-07-12T21:54:20.179422Z",
     "iopub.status.idle": "2022-07-12T21:54:21.034754Z",
     "shell.execute_reply": "2022-07-12T21:54:21.033486Z"
    },
    "papermill": {
     "duration": 7.047838,
     "end_time": "2022-07-12T21:54:21.037221",
     "exception": false,
     "start_time": "2022-07-12T21:54:13.989383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'transformers': Is a directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm transformers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 32344.936812,
   "end_time": "2022-07-12T21:54:30.756170",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-12T12:55:25.819358",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
